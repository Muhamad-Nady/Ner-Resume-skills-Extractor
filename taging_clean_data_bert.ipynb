{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown] {\"id\":\"vf-OWJJ1NOQs\"}\n# ## CREATE clean corpus to extract skills\n\n# %% [code] {\"id\":\"QLiBredkD8bK\",\"outputId\":\"c6f8e49f-fe00-420d-c02f-550fc2bccc34\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T12:32:15.979863Z\",\"iopub.execute_input\":\"2023-03-08T12:32:15.980577Z\",\"iopub.status.idle\":\"2023-03-08T12:32:55.041517Z\",\"shell.execute_reply.started\":\"2023-03-08T12:32:15.980535Z\",\"shell.execute_reply\":\"2023-03-08T12:32:55.040331Z\"}}\n!pip install clean-text\n#!pip uninstall emoji -y\n!pip install emoji==1.7\n!pip install clean-text[gpl]\n\n# %% [code] {\"id\":\"0X3NfAlXM0h6\",\"outputId\":\"365b2455-9ec4-471a-e15a-31e9982819dc\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:05:39.332141Z\",\"iopub.execute_input\":\"2023-03-08T00:05:39.332543Z\",\"iopub.status.idle\":\"2023-03-08T00:05:39.492429Z\",\"shell.execute_reply.started\":\"2023-03-08T00:05:39.332509Z\",\"shell.execute_reply\":\"2023-03-08T00:05:39.490957Z\"}}\n# read corpus data 208M\nwith open(\"/kaggle/input/bert-dataset/resume_samples.txt\", 'rb') as f:\n  text = f.read()\n#text = text[0:2138212]\nprint(len(text))\n\n# %% [code] {\"id\":\"Jq58StkTFs45\",\"outputId\":\"0bee45d5-6c35-4be4-dd94-9ef48337264f\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:05:42.257397Z\",\"iopub.execute_input\":\"2023-03-08T00:05:42.258680Z\",\"iopub.status.idle\":\"2023-03-08T00:14:55.282681Z\",\"shell.execute_reply.started\":\"2023-03-08T00:05:42.258629Z\",\"shell.execute_reply\":\"2023-03-08T00:14:55.281433Z\"}}\n%%time\n## cleaning corpus with cleantetx fun\nfrom cleantext import clean\nnew_txt = clean(text, lower=False,\n    fix_unicode=True,\n    to_ascii=True,\n    normalize_whitespace=False,\n    no_line_breaks=False,\n    strip_lines=True,\n    keep_two_line_breaks=False,\n    no_urls=True,\n    no_emails=False,\n    no_phone_numbers=True,\n    no_numbers=True,\n    no_digits=True,\n    no_currency_symbols=True,\n    no_punct=False,\n    no_emoji=True,\n    replace_with_url=\"\",\n    replace_with_email=\"\",\n    replace_with_phone_number=\"\",\n    replace_with_number=\"\",\n    replace_with_digit=\"\",\n    replace_with_currency_symbol=\"\",\n    replace_with_punct=\" \",\n    lang=\"en\",)\nprint(new_txt[0:1000])\n\n# %% [code] {\"id\":\"bFtDnN8Ih5hZ\",\"outputId\":\"f50e9d70-4d15-46fe-d4dd-0f8780bc5899\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:14:55.285031Z\",\"iopub.execute_input\":\"2023-03-08T00:14:55.285881Z\",\"iopub.status.idle\":\"2023-03-08T00:14:55.623952Z\",\"shell.execute_reply.started\":\"2023-03-08T00:14:55.285839Z\",\"shell.execute_reply\":\"2023-03-08T00:14:55.622555Z\"}}\nimport re\n# as per recommendation from @freylis, compile once only\nCLEANR = re.compile('<.*?>') \n\ndef cleanhtml(new_txt):\n  cleantext = re.sub(CLEANR, '', new_txt)\n  return cleantext\ntext = cleanhtml(new_txt)\nprint(new_txt[0:1000])\n\n# %% [code] {\"id\":\"mkf_cD4CRA_I\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:14:55.625593Z\",\"iopub.execute_input\":\"2023-03-08T00:14:55.626180Z\",\"iopub.status.idle\":\"2023-03-08T00:15:08.974908Z\",\"shell.execute_reply.started\":\"2023-03-08T00:14:55.626139Z\",\"shell.execute_reply\":\"2023-03-08T00:15:08.973862Z\"}}\n# split sentences with \".\"\nsentences_pun = text.split(\".\")\nsentences = []\n## removing Punct from sentneces:\nfor sentnece in sentences_pun: \n  \n  # Removing punctuations in string\n  # Using regex\n  if (len(sentnece.split()) > 10):\n    sentence_md = re.sub(r'[^\\w\\s]', ' ', sentnece)\n    # strip() all word in sentence\n    sentence_md = [x.strip() for x in sentence_md.split()]\n    sentences.append(\" \".join(sentence_md).lower())\n  else:\n    pass\n  #print(sentences[row])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:08.977369Z\",\"iopub.execute_input\":\"2023-03-08T00:15:08.977742Z\",\"iopub.status.idle\":\"2023-03-08T00:15:08.998501Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:08.977691Z\",\"shell.execute_reply\":\"2023-03-08T00:15:08.997096Z\"}}\nnew_sent = [\"Good Command of both English & Arabic Languages\", \"Must be a graduate\", \n            \"eriences in a development role for Microsoft Dynamics\", \"Solid understanding of Programming languages concepts and OOP\",\n            \"Solid understating of Data base concepts\",\n            \"Microsoft NET technology ,Microsoft Visual Studio development system and SQL Server Management Studio\",\n            \"Web Services and Microsoft Office SharePoint Portal Server\",\n            \"Solid understanding of Microsoft technology stack\",\n            \"Understanding of key independent software vendors (ISVs) within the defined vertical(s)\",\n           \"Proficiency in the following skills and technologies is mandatory CSS, HTML5, Bootstrap,jQuery Adobe Creative\", \n            \"and/or CorelDraw Graphics SuiteBootstrap, AngularJS Proficiency in the following technologies is desired but not mandatory\"]\nfor i, _ in enumerate(new_sent):\n    new_sent[i] = _.lower()\n    \nsentences_ = new_sent + sentences\n\n# %% [code] {\"id\":\"wRCIkxwd5kIZ\",\"outputId\":\"9d57cb50-fa6e-4906-c7ab-122db65fa4c5\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:09.000022Z\",\"iopub.execute_input\":\"2023-03-08T00:15:09.000389Z\",\"iopub.status.idle\":\"2023-03-08T00:15:09.020601Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:09.000355Z\",\"shell.execute_reply\":\"2023-03-08T00:15:09.019316Z\"}}\n# adding non skill to sentence[0] for labled as \"O\" in tag2id\nsentences_[11] = \"i am using \" + sentences_[11]\nsentences_[11]\n\n# %% [code] {\"id\":\"6fvxl4tN6pdV\",\"outputId\":\"3245a0bf-b824-4a1e-fbae-225a9392b22c\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:09.022129Z\",\"iopub.execute_input\":\"2023-03-08T00:15:09.022483Z\",\"iopub.status.idle\":\"2023-03-08T00:15:09.278955Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:09.022451Z\",\"shell.execute_reply\":\"2023-03-08T00:15:09.277645Z\"}}\n## saved cleaned data as df\nimport pandas as pd\ncorpus_df = pd.DataFrame(sentences_, columns=[\"sentences\"])\ncorpus_df.head()\n\n# %% [code] {\"id\":\"8Z_24uLLXUKE\",\"outputId\":\"d48ed367-7523-4bc4-f6c5-2623920bf305\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:09.280585Z\",\"iopub.execute_input\":\"2023-03-08T00:15:09.281517Z\",\"iopub.status.idle\":\"2023-03-08T00:15:09.287535Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:09.281476Z\",\"shell.execute_reply\":\"2023-03-08T00:15:09.286269Z\"}}\n#some info about (sentences)\nprint(len(sentences))\n\n# %% [markdown] {\"id\":\"5trMEaGo73yu\"}\n# ## prepare Skills DataFram\n\n# %% [code] {\"id\":\"YiR0BZMn73GF\",\"outputId\":\"41c80b49-386e-4939-8ef2-d1339430661f\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:09.289274Z\",\"iopub.execute_input\":\"2023-03-08T00:15:09.289660Z\",\"iopub.status.idle\":\"2023-03-08T00:15:09.330766Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:09.289627Z\",\"shell.execute_reply\":\"2023-03-08T00:15:09.329649Z\"}}\n# reading skill data preped of kaggle data\nimport pandas as pd\nimport re\nskill_df = pd.read_csv(\"/kaggle/input/bert-dataset/skills_df.csv\")\nprint(skill_df.shape)\nskill_df.head()\n\n# %% [code] {\"id\":\"N8a-RftP8Gj8\",\"outputId\":\"301cebd8-9558-4877-c673-66bb3f7e33cc\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:09.332161Z\",\"iopub.execute_input\":\"2023-03-08T00:15:09.332563Z\",\"iopub.status.idle\":\"2023-03-08T00:15:14.011697Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:09.332498Z\",\"shell.execute_reply\":\"2023-03-08T00:15:14.010493Z\"}}\n# Reading tech skill data\nskill_df_ex = pd.read_excel(\"/kaggle/input/bert-dataset/Technology Skills.xlsx\")\nprint(skill_df_ex.shape)\nskill_df_ex.head()\n\n# %% [code] {\"id\":\"MIPTWU-yUouP\",\"outputId\":\"6d1352fc-5e8f-4ff6-f579-1faf39335b0f\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:14.017334Z\",\"iopub.execute_input\":\"2023-03-08T00:15:14.018036Z\",\"iopub.status.idle\":\"2023-03-08T00:15:14.138735Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:14.017992Z\",\"shell.execute_reply\":\"2023-03-08T00:15:14.137285Z\"}}\n## Cleaning un important word in skills like \" hands on, exceprience\"\nimport numpy as np\nskill_df_ex['Example'] = skill_df_ex['Example'].str.lower()\nskill_df_ex['Example'] = skill_df_ex['Example'].apply(lambda x: x.replace(\"hands on\",''))\nskill_df_ex['Example'] = skill_df_ex['Example'].apply(lambda x: x.replace(\"experience in\",''))\nskill_df_ex['Example'] = skill_df_ex['Example'].apply(lambda x: x.replace(\"experience on\",''))\nskill_df_ex['Example'] = skill_df_ex['Example'].apply(lambda x: x.replace(\"and\",''))\nskill_df_ex['Example'] = skill_df_ex['Example'].apply(lambda x: x.replace(r'\\d',''))\nskill_df_ex['Example'] = skill_df_ex['Example'].apply(lambda x: x.replace(r'[^A-Za-z\\s]',''))\n## removing linkedin out of skills\nind = skill_df_ex[skill_df_ex[\"Example\"].str.contains(\"linkedin\")].index\nskill_df_ex = skill_df_ex.drop(ind)\n\n# %% [code] {\"id\":\"Srx3Uwn92VZI\",\"outputId\":\"6cd76ebb-d322-4d00-d5cc-f04f56c3203b\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:14.140163Z\",\"iopub.execute_input\":\"2023-03-08T00:15:14.140551Z\",\"iopub.status.idle\":\"2023-03-08T00:15:14.191237Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:14.140512Z\",\"shell.execute_reply\":\"2023-03-08T00:15:14.189805Z\"}}\n## reading skills gatherd by Ghazali\nfinal_skill = pd.read_csv(\"/kaggle/input/bert-dataset/last_skills.csv\")\nfinal_skill.drop([\"Unnamed: 0\"], axis=1, inplace=True)\nfinal_skill.rename(columns = {\"0\": \"skill\"}, inplace=True)\nfinal_skill.reset_index(drop=True)\nfinal_skill.head()\n\n# %% [code] {\"id\":\"kG1sUcdC8Giv\",\"outputId\":\"45b5ae10-5975-4f0f-e65e-9ba4c2a3364f\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:14.193805Z\",\"iopub.execute_input\":\"2023-03-08T00:15:14.195082Z\",\"iopub.status.idle\":\"2023-03-08T00:15:14.226748Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:14.195027Z\",\"shell.execute_reply\":\"2023-03-08T00:15:14.225532Z\"}}\n## contcating two column of skills from diff df\n#concated_skill = skill_df[\"Text\"].concat(df[\"Example\"])\nconcated_skill = pd.concat([skill_df[\"Text\"], skill_df_ex[\"Example\"], final_skill[\"skill\"]])\nconcated_skill_df = pd.DataFrame(concated_skill, columns=[\"Text\"])\nconcated_skill_df = concated_skill_df.reset_index(drop=True)\n#concated_skill_df.drop([\"index\"], axis=1, inplace=True)\nprint(concated_skill_df.info())\nconcated_skill_df.tail()\n\n# %% [code] {\"id\":\"0y5T9T2k3mvM\",\"outputId\":\"c3d007dc-96eb-4733-b4cc-1982c885e678\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:14.228451Z\",\"iopub.execute_input\":\"2023-03-08T00:15:14.229617Z\",\"iopub.status.idle\":\"2023-03-08T00:15:14.288846Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:14.229561Z\",\"shell.execute_reply\":\"2023-03-08T00:15:14.287409Z\"}}\n# Removing any sing except [A-Za-z1-9_]\nconcated_skill_df['Text'] = concated_skill_df['Text'].str.replace('[^A-Za-z\\s]', '', regex=True)\nconcated_skill_df[\"Text\"]\n\n# %% [code] {\"id\":\"qITsZH2z-cwZ\",\"outputId\":\"cb0a6b5f-6dc5-4153-d2fd-b1e5dee6c976\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:14.290498Z\",\"iopub.execute_input\":\"2023-03-08T00:15:14.290898Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.023117Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:14.290862Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.021732Z\"}}\n#Split skills into three words with two columns\nconcated_skill_df[[\"B-SKILL\", \"I-SKILL\"]] = concated_skill_df[\"Text\"].str.split(\" \",n=1, expand=True)\nconcated_skill_df[[\"I-SKILL\", \"O-SKILL\"]] = concated_skill_df[\"I-SKILL\"].str.split(\" \",n=1, expand=True)\nconcated_skill_df[[\"O-SKILL\", \"L-SKILL\"]] = concated_skill_df[\"O-SKILL\"].str.split(\" \",n=1, expand=True)\nconcated_skill_df.fillna(\"\", inplace=True)\nconcated_skill_df.tail()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.026826Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.027987Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.067614Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.027939Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.066005Z\"}}\n## drop Duplicates\nconcated_skill_df.drop_duplicates([\"B-SKILL\", \"I-SKILL\", \"O-SKILL\"], inplace=True)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.069464Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.069924Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.091463Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.069885Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.090276Z\"}}\n## I-SKILL as and O-SKIll as \"\"\nind = concated_skill_df[(concated_skill_df[\"I-SKILL\"].isin([\"and\", \"of\", \"the\", \"in\", \"to\", \"at\", \"with\"])) & (concated_skill_df[\"O-SKILL\"] == \"\")].index\nconcated_skill_df.drop(ind, axis=0, inplace=True)\nind = concated_skill_df[(concated_skill_df[\"I-SKILL\"].isin([\"on\"])) & (concated_skill_df[\"O-SKILL\"] == \"\")].index\nconcated_skill_df.loc[ind, \"I-SKILL\"] = \"\"\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.093252Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.093787Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.103870Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.093731Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.102580Z\"}}\n## O-SKill as and\nind = concated_skill_df[concated_skill_df[\"O-SKILL\"].isin([\"and\", \"of\", \"the\", \"in\", \"to\", \"at\", \"with\", \"on\"])].index\nconcated_skill_df.loc[ind, \"O-SKILL\"] = \"\"\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.105888Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.106582Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.122850Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.106530Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.121099Z\"}}\n## I-SKILL as and O-SKIll as \"word\"\npd.set_option('display.max_rows', 500)\nind = concated_skill_df[(concated_skill_df[\"I-SKILL\"].isin([\"and\", \"of\", \"the\", \"in\", \"to\", \"at\", \"with\"]))].index\nconcated_skill_df.drop(ind, axis=0, inplace=True)\n\n# %% [code] {\"id\":\"wmK7gxcoAgqt\",\"outputId\":\"f0207566-ce65-47f9-fc86-d479a6fa03c9\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.124961Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.125346Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.175679Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.125308Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.174165Z\"}}\n\n## conevrt skills df to list\n## begning of creating skills_ls\nskills_ls = concated_skill_df[\"B-SKILL\"] + \" \" + concated_skill_df[\"I-SKILL\"] + \" \" + concated_skill_df[\"O-SKILL\"]\nskills_ls = skills_ls.apply(str.lower)\nskills_ls = skills_ls.unique()\n#skills_ls.to_csv(\"skills.csv\")\nskills_ls = skills_ls.tolist()\nskills_ls = set(skills_ls)\nskills_ls = list(skills_ls)\nskills_ls.extend([\"aws\", \"ssis\", \"backend\", \"nodejs\", \"net core\", \"aspnet\", \"expressjs\",\"reactjs\", \"microsoft net\", \"ms net\", \"AngularJS\"])\nskills_ls.sort(key=lambda item: (-len(item), item))\nprint(len(skills_ls), skills_ls[-90:-1])\n\n# %% [code] {\"id\":\"nuXQEv7osGWd\",\"outputId\":\"e103e4d6-2032-42d2-872b-f34f9269f97b\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.177210Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.177578Z\",\"iopub.status.idle\":\"2023-03-08T00:15:15.193350Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.177541Z\",\"shell.execute_reply\":\"2023-03-08T00:15:15.191905Z\"}}\n## Removing digits from skills\nskills_ls = [x for x in skills_ls if not x.isdigit()]\nskills_ls = [x for x in skills_ls if not isinstance(x, int)]\nprint(len(skills_ls), skills_ls[7000:7020])\n\n# %% [code]\n\n\n# %% [code] {\"id\":\"sHM07Dk9uCXL\",\"outputId\":\"64243657-52c2-480f-c5f1-b34eeb2d3f10\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:15.195111Z\",\"iopub.execute_input\":\"2023-03-08T00:15:15.195473Z\",\"iopub.status.idle\":\"2023-03-08T00:15:16.722177Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:15.195440Z\",\"shell.execute_reply\":\"2023-03-08T00:15:16.720543Z\"}}\n## serching some pattern in skill list\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nskills_ls = [x.strip() for x in skills_ls]\npunctuation_ls = list(set(punctuation))\nstop_word = stopwords.words('english')\ndigit = [\"1\",\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\nsome_other_words = ['security', 'high availability','programming languages','immunohistochemistry', 'family planning', 'collateral',\n                    'print', 'simulation', 'reports', 'designs', 'and', 'mobility', 'that', 'range', 'schedules', 'this', 'testing',\n                    'visual', 'ordering', 'office', 'family engagement', 'ued', 'rotation', 'road', 'daily', 'system', 'modifications',\n                    'concepts', 'environmental site', 'family holidays', 'github.com', 'investigations', 'signing', 'company turn around',\n                    'subcontracts', 'to', 'company', 'credit', 'word', 'funding', 'segmentation', 'proposal', 'bids', 'asphalt', 'irrigation',\n                    'one', 'operations', 'linkedin', 'instrumental', 'change', 'customer', 'build', 'reporting', 'family vacations', 'draft',\n                    'website', 'company research', 'quality', 'current', 'real-time', 'livelihood', 'controls', 'family office', 'server',\n                    'monitoring', 'resource', 'survey', 'union', 'investigate', 'a', 'summary', 'structures', 'resolve',\n                    'large group interventions', 'material', 'family mediation', 'content', 'schedule', 'materials', 'story', 'interfaces',\n                    'cedar', 'month', 'branding', 'design', 'illumination', 'emotional disabilities', 'the', 'provider-1', 'family of origin',\n                    'oversight', 'skills', 'family services', 'xml path', 'survey monkey', 'enterprise', 'distribution', 'free', 'payments',\n                    'affinity', 'options',\"hands\",'focus', 'maintain', 'learn hq', 'engineering', 'xml user', 'constructability', 'brochures',\n                    'operating systems', 'Plan', 'family reunions', 'company naming', 'web page', 'events', 'updates', 'art', 'base', 'freeway',\n                    'building', 'family fitness', 'pro', 'tracheostomy', 'prototype', 'vendors', 'family history', 'documents', 'campus', 'highcharts',\n                    'cash', 'non-union', 'audit', 'highways', 'family literacy', 'advanced', 'business', 'texas', 'concrete', 'installanywhere',\n                    'coordinated', 'civil', 'campaigns', 'family rooms', 'i', 'company picnics', 'project', 'metrics', 'brand', 'drainage', 'deliveries',\n                    'transportation', 'sales', 'award', 'reception areas', 'metro', 'youtube', 'engage', 'pay', 'networking', 'point of', 'job', 'control',\n                    'masterpiece', 'languages', 'startup', 'projects', 'articles', 'day', 'less', 'environmental', 'in the news', 'library', 'teams',\n                    'transport', 'cash flow', 'release', 'family events', 'segment', 'general', 'time and', 'publications', 'best', 'bridge', 'budgets',\n                    'overclocking', 'landscaping', 'performing', 'salary', 'is', 'preparation', 'family partnerships', 'installation', 'proposals',\n                    'software', 'mad', 'international', 'text box', 'technical', 'family care', 'outages', 'serverless', 'it', 'other', 'resources',\n                    'support', 'revenue', 'company brochures', 'projection', 'simulation system', 'political asylum', 'company newsletters', 'net',\n                    'follow-on offerings', 'change orders', 'basic', 'grading', 'enscribe', 'an', 'flow', 'optimizer', 'framework', 'training',\n                    'process', 'soil', 'promotional', 'family policy', 'development', 'monthly', 'video', 'natural languages', 'technologies',\n                    'operating system', '.','ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out',\n                    'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself',\n                    'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these',\n                    'your', 'his', 'through', 'don', 'nor',\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\"\n                    , \"to\", \"and\",'summary','skills','schedule','company naming'\n                    ,'operations','system','outages','draft','union','non-union'\n                    ,'salary','vendors','resolve','real-time','metrics','articles'\n                    ,'updates','story','content','events','branding','sales','video'\n                    ,'design','website','networking','audit','visual','process'\n                    ,'company','print','collateral','campaigns','promotional'\n                    ,'publications','distribution','credit','options','campus'\n                    ,'brand','base','affinity','flow','Plan','focus','engage','reception areas'\n                    ,'art','brochures','customer','pro','startup','overclocking'\n                    ,'family events','installanywhere','in the news','emotional disabilities'\n                    ,'mad','follow-on offerings','prototype','large group interventions'\n                    ,'ued','optimizer','masterpiece','political asylum','immunohistochemistry'\n                    ,'provider-1','tracheostomy','livelihood','basic','enscribe','testing'\n                    ,'software','support','server','rotation','business','release','monitoring'\n                    ,'segment','segmentation','payments','cash flow','serverless','projects','range'\n                    ,'award','cedar','general','technical','ordering','concepts','drainage','survey'\n                    ,'survey monkey','word','asphalt','change orders','controls','illumination'\n                    ,'reporting','proposal', 'performing','soil','oversight','materials'\n                    ,'enterprise','preparation','teams','projection','freeway','highways'\n                    ,'other','constructability','grading','landscaping','concrete','pay'\n                    ,'revenue','transport','less','office','mobility','road','instrumental'\n                    ,'investigate','bridge','metro','advanced','texas','engineering','bids'\n                    ,'subcontracts','coordinated','international','interfaces','funding'\n                    ,'transportation','deliveries','irrigation','structures','reports'\n                    ,'investigations','training','environmental site','project','installation'\n                    ,'building','modifications','company brochures','company newsletters'\n                    ,'company picnics','company turn around','company research','family policy'\n                    ,'family literacy','family engagement','family history','family history'\n                    ,'family planning','family reunions','family care','family of origin'\n                    ,'family holidays','family office','family mediation','family rooms'\n                    ,'family services','family fitness','family partnerships','family vacations'\n                    ,'budgets','highcharts','i','control','schedules','change','environmental'\n                    ,'quality','resource','resources','designs','development','build','civil'\n                    ,'proposals','maintain','documents','material','one','cash','signing'\n                    ,'mar','in', '.','search','https','ieee','organization','application'\n                    ,'datasets','models','online','stack','languages','records','healthcare'\n                    ,'linkedin','space','learning','lighting','o','waste','arabic','x'\n                    ,'x 10.1','x 10.2','x 10.3','status','landscape','tender','d' ,'n','f'\n                    ,'birth','birth certificates','birth announcements','birth injury'\n                    ,'ee','beam','engineers','cable','data','programming','multinational'\n                    ,'military','english','si','robot','cables','p','electrical','syndicate',\n                    'sockets', 'programming languages']\nneglected_item = punctuation_ls + stop_word + digit + some_other_words\nfor item in neglected_item:\n  if item in skills_ls:\n    skills_ls.remove(item)\n  else:\n    pass\nprint(len(skills_ls), skills_ls[0:10])\n\n# %% [code] {\"id\":\"_G_9F6u0vsNl\",\"outputId\":\"040e70b3-40d4-45f7-dff3-3bc45d5e5064\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:16.723980Z\",\"iopub.execute_input\":\"2023-03-08T00:15:16.724349Z\",\"iopub.status.idle\":\"2023-03-08T00:15:16.738275Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:16.724313Z\",\"shell.execute_reply\":\"2023-03-08T00:15:16.736573Z\"}}\n## remove some skills out of skills_ls\nimport re\nr = re.compile(\".*university\")\nnewlist = list(filter(r.match, skills_ls)) # Read Note below\nfor skill in newlist:\n  skills_ls.remove(skill)\nprint(len(skills_ls), skills_ls[0:10])\n\n# %% [code] {\"id\":\"yvKLHGKCbMFz\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:16.739694Z\",\"iopub.execute_input\":\"2023-03-08T00:15:16.740112Z\",\"iopub.status.idle\":\"2023-03-08T00:15:16.748572Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:16.740075Z\",\"shell.execute_reply\":\"2023-03-08T00:15:16.746493Z\"}}\n# # trying to iterat over df.values but iteration over list 4.95ms for 10 records, itreate over df.values 7.49ms\n# ## conevrt skills df to list\n# skills_ls = concated_skill_df[\"B-Skill\"] + \" \" + concated_skill_df[\"I-Skill\"]\n# skills_ls = skills_ls.apply(str.lower)\n# skills_ls = skills_ls.unique()\n# df_skills_ls = pd.DataFrame(skills_ls, columns=[\"Skills\"])\n# ## converting list to arry and check the performanece of iteration\n# df_skills_ls[\"Skills\"].values\n\n# %% [code] {\"id\":\"gudZJyspcjIB\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:16.750779Z\",\"iopub.execute_input\":\"2023-03-08T00:15:16.751363Z\",\"iopub.status.idle\":\"2023-03-08T00:15:16.759238Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:16.751322Z\",\"shell.execute_reply\":\"2023-03-08T00:15:16.757585Z\"}}\n# ## converting the list to numpay array and check time of excution\n# skill_arr = np.array(skills_ls)\n# print(type(skill_arr), skill_arr[1:10])\n\n# %% [code] {\"id\":\"9pFpN20QL9-_\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:16.761156Z\",\"iopub.execute_input\":\"2023-03-08T00:15:16.761596Z\",\"iopub.status.idle\":\"2023-03-08T00:15:16.796225Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:16.761558Z\",\"shell.execute_reply\":\"2023-03-08T00:15:16.794952Z\"}}\n## cobert skills to csv\nfin_ls_skills = pd.DataFrame({\"skills\":skills_ls})\nprint(fin_ls_skills.shape)\nfin_ls_skills.to_csv(\"/kaggle/working/fin_ls_skills.csv\", index=False)\n\n# %% [markdown] {\"id\":\"Xcs7FJCAi0Vt\"}\n# ## Creating label for data \n# ###text = sentences\n# ###skills = skill_ls\n\n# %% [code] {\"id\":\"nKGFov0f4U5K\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T00:15:16.797753Z\",\"iopub.execute_input\":\"2023-03-08T00:15:16.798129Z\",\"iopub.status.idle\":\"2023-03-08T06:36:52.278801Z\",\"shell.execute_reply.started\":\"2023-03-08T00:15:16.798093Z\",\"shell.execute_reply\":\"2023-03-08T06:36:52.277843Z\"}}\n%%time\n## extract sentences with skills\n## optomized by Nady\nimport re\ndf2 = pd.DataFrame(columns=[\"sentence_id\", \"word\", \"word_mdf\"])\nfor row, sentence in enumerate(sentences_[0:20000]):\n  sentence_cp = sentence\n  for skill in skills_ls:\n      if (len(skill.split()) == 1):\n        for ser in  re.finditer(rf'\\b{skill}\\b', sentence):\n          if ser != None:\n            sentence = re.sub(rf\"\\b{skill}\\b\", \"B-SKILL\", sentence)\n          else:\n            pass\n      elif (len(skill.split()) == 2):    \n        for ser in re.finditer(rf'\\b{skill}\\b', sentence):\n          if ser != None:\n            sentence = re.sub(rf\"\\b{skill}\\b\", \"B-SKILL I-SKILL\", sentence)\n          else:\n            pass\n      elif (len(skill.split()) == 3):    \n        for ser in re.finditer(rf'\\b{skill}\\b', sentence):\n          if ser != None:\n            sentence = re.sub(rf\"\\b{skill}\\b\", \"B-SKILL I-SKILL O-SKILL\", sentence)\n          else:\n            pass\n  try:\n    token_sentence_cp = sentence_cp.split()\n    token_sentence = sentence.split()\n    sentence_id = [f'sentence_{row}']*len(token_sentence)\n    token_df = pd.DataFrame({\"sentence_id\":sentence_id,\"word\":token_sentence_cp, \"word_mdf\": token_sentence})\n    df2 = pd.concat([df2, token_df])\n  except Exception as e:\n    print(f\"sentence_#: {row}\", len(sentence.split()), len(sentence_cp.split()), sep=\",\")\n    print(sentence, sentence_cp, sep=\"\\n\")\n\n# %% [code] {\"id\":\"VBAD4BNlFf5Q\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T06:36:52.279942Z\",\"iopub.execute_input\":\"2023-03-08T06:36:52.280773Z\",\"iopub.status.idle\":\"2023-03-08T06:36:52.499020Z\",\"shell.execute_reply.started\":\"2023-03-08T06:36:52.280702Z\",\"shell.execute_reply\":\"2023-03-08T06:36:52.497435Z\"}}\n#df2[\"sentence #\"].unique()\nimport numpy as np\ndf2[\"tag\"] = \"O\"\ndf_taged = df2.reset_index(drop=True)\nindex = np.where(df_taged[\"word\"] != df_taged[\"word_mdf\"])\nprint(len(index[0]))\ndf_taged.loc[index[0],\"tag\"] = df_taged.loc[index[0],\"word_mdf\"]\n\n# %% [code] {\"id\":\"XH2Ndmdf4lFk\",\"execution\":{\"iopub.status.busy\":\"2023-03-08T08:41:10.487779Z\",\"iopub.execute_input\":\"2023-03-08T08:41:10.488192Z\",\"iopub.status.idle\":\"2023-03-08T08:41:11.877469Z\",\"shell.execute_reply.started\":\"2023-03-08T08:41:10.488159Z\",\"shell.execute_reply\":\"2023-03-08T08:41:11.876387Z\"}}\n#df_taged.to_csv(\"/content/drive/MyDrive/Bert/df_tagedforbert.csv\")\n#df_taged.to_csv(\"/content/df_tagedforbert_:15.csv\")\ndf_taged.to_csv(\"/kaggle/working/20.csv\")\n# df_taged.to_csv(\"/content/drive/MyDrive/Bert/15K.csv\")\n#df_taged[100:150]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-08T08:40:52.502440Z\",\"iopub.execute_input\":\"2023-03-08T08:40:52.502866Z\",\"iopub.status.idle\":\"2023-03-08T08:40:52.587130Z\",\"shell.execute_reply.started\":\"2023-03-08T08:40:52.502826Z\",\"shell.execute_reply\":\"2023-03-08T08:40:52.585801Z\"}}\nimport pandas as pd\n# df_taged = pd.read_csv(\"/kaggle/working/20.csv\")\nind = df_taged[df_taged[\"word\"] == \"html5,\"].index\ndf_taged.loc[ind, [\"word\",\"tag\"]] = [\"html5\", \"B-SKILL\"]\n#df_taged.loc[ind+1, [\"word\",\"tag\"]] = [\"jquery\", \"B-SKILL\"]\ndf_taged[50:100]\n\n# %% [markdown]\n# \n\n# %% [raw] {\"execution\":{\"iopub.status.busy\":\"2023-03-05T09:36:48.131444Z\",\"iopub.execute_input\":\"2023-03-05T09:36:48.131913Z\",\"iopub.status.idle\":\"2023-03-05T09:36:48.410928Z\",\"shell.execute_reply.started\":\"2023-03-05T09:36:48.131883Z\",\"shell.execute_reply\":\"2023-03-05T09:36:48.409420Z\"}}\n# # ## concat created df\n# df_1 = pd.read_csv(\"/kaggle/working/20K.csv\")\n# # df_6 = pd.read_csv(\"/kaggle/working/40K.csv\")\n# \n# # df_taged_40K = pd.concat([df_1, df_6])\n# # # df_taged_11K.head()\n# # df_taged_40K.to_csv(\"/kaggle/working/df_taged_40K.csv\", index=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-03-05T09:37:10.335214Z\",\"iopub.execute_input\":\"2023-03-05T09:37:10.335641Z\",\"iopub.status.idle\":\"2023-03-05T09:37:10.354384Z\",\"shell.execute_reply.started\":\"2023-03-05T09:37:10.335610Z\",\"shell.execute_reply\":\"2023-03-05T09:37:10.352166Z\"}}\ndf_1[-50:-1]\n\n# %% [markdown] {\"id\":\"G9DNgiWS4zLG\"}\n# # End of ipynb","metadata":{"_uuid":"8744ab67-b199-483f-bfa8-e8b35516aab2","_cell_guid":"90430160-beb6-458a-aa62-3232b4bb3a4d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}